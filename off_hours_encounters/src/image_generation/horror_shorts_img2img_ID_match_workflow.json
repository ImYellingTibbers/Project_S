{
  "35": {
    "inputs": {
      "image": "canon (2).png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Canon Image"
    }
  },
  "37": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "38": {
    "inputs": {
      "weight": 0.75,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0.05,
      "end_at": 0.75,
      "embeds_scaling": "K+V",
      "model": [
        "58",
        0
      ],
      "ipadapter": [
        "40",
        0
      ],
      "image": [
        "35",
        0
      ],
      "clip_vision": [
        "37",
        0
      ]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": {
      "title": "IPAdapter Advanced"
    }
  },
  "40": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus-face_sdxl_vit-h.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "IPAdapter Model Loader"
    }
  },
  "50": {
    "inputs": {
      "text": "different person, face mismatch, identity change, face swap,\nincorrect face, altered identity,\n\nbeauty retouching, model-like appearance, idealized features,\nplastic skin, overly smooth skin, airbrushed face,\n\nexaggerated facial features, stylized face, cartoon face,\ncgi face, digital face,\n\ndistorted face, warped face, melted face,\nduplicated face, asymmetrical eyes,\nmisaligned pupils, extra eyes, extra ears,\n\nblurry face, low detail face, out of focus face\n",
      "clip": [
        "58",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "NEGATIVE"
    }
  },
  "58": {
    "inputs": {
      "ckpt_name": "RealVisXL_V5.0_fp16.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint - BASE"
    }
  },
  "61": {
    "inputs": {
      "seed": 34928734510955,
      "steps": 15,
      "cfg": 5,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "denoise": 0.3,
      "model": [
        "38",
        0
      ],
      "positive": [
        "100",
        0
      ],
      "negative": [
        "50",
        0
      ],
      "latent_image": [
        "103",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSAMPLER_ID_LOCK"
    }
  },
  "62": {
    "inputs": {
      "samples": [
        "61",
        0
      ],
      "vae": [
        "58",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE_DECODE_B"
    }
  },
  "63": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "104",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "SAVE_IMAGE"
    }
  },
  "96": {
    "inputs": {
      "image": "beat_003.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Beat Image"
    }
  },
  "100": {
    "inputs": {
      "text": "same person as reference image,\npreserve original scene and composition,\npreserve lighting and camera angle,\npreserve clothing and body proportions,\nsubtle correction only,\nphotorealistic,\nnatural skin texture,\nno beautification\n",
      "clip": [
        "58",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "POSITIVE"
    }
  },
  "103": {
    "inputs": {
      "pixels": [
        "96",
        0
      ],
      "vae": [
        "58",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "104": {
    "inputs": {
      "guide_size": 512,
      "guide_size_for": true,
      "max_size": 1024,
      "seed": 225323591093272,
      "steps": 12,
      "cfg": 8,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.5,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.5,
      "bbox_dilation": 10,
      "bbox_crop_factor": 3,
      "sam_detection_hint": "center-1",
      "sam_dilation": 0,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": "",
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "tiled_encode": false,
      "tiled_decode": false,
      "image": [
        "62",
        0
      ],
      "model": [
        "58",
        0
      ],
      "clip": [
        "58",
        1
      ],
      "vae": [
        "58",
        2
      ],
      "positive": [
        "100",
        0
      ],
      "negative": [
        "50",
        0
      ],
      "bbox_detector": [
        "105",
        0
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "FaceDetailer"
    }
  },
  "105": {
    "inputs": {
      "model_name": "bbox/face_yolov8n.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  }
}